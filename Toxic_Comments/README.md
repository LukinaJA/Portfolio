# Toxic_Comments

### Проект классификации комментариев

 *Цель проекта: построить модель со значением метрики качества F1 не меньше 0.75 для классификации комментариев на позитивные и негативные*

### Шаги проекта:

- подготовить данные,
- проверить датасет на сбалансированность,
- очистить и лемматизировать текст,
- создать и почистить мешок слов,
- разделить данные на выборки и определить целевой признак,
- вычислить TF-IDF для тренировочной и тестовой выборок,
- обучить модели логистическая регрессия и CatBoostClassifier,
- сделать выводы.

## Выводы:

- пропусков не обнаружено, типы данных соответствуют заявленным, удален неинформативный столбец;
- данные несбалансированны: 10 процентов приходится на токсичные комментарии;
- текст очищен и лемматизирован, проведен частотный анализ текста;
- данные разделены на выборки и определен целевой признак,
- вычислен TF-IDF для тренировочной и тестовой выборок,
- обучены модели логистическая регрессия и CatBoostClassifier;
- лучший результат метрики f1 для Логистической регрессии - 0,766, для CatBoostClassifier - 0.90, время подсчета - 14 и 25 минут соответственно.
  
Проверка модели на тестовых данных показала результат метрики f1 - 0.75, что соответствует заявленным требованиям

Таким образом, применение модели CatBoostClassifier на основе метода оценки важности слов TF-IDF может быть рекомендована для поиска токсичных комментариев.
